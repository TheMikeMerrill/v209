---
title: Self-Supervised Pretraining and Transfer Learning Enable\titlebreak Flu and
  COVID-19 Predictions in Small Mobile Sensing Datasets
abstract: Detailed mobile sensing data from phones and fitness trackers offer an opportunity
  to quantify previously unmeasurable behavioral changes to improve individual health
  and accelerate responses to emerging diseases. Unlike in natural language processing
  and computer vision, deep learning has yet to broadly impact this domain, in which
  the majority of research and clinical applications still rely on manually defined
  features or even forgo predictive modeling altogether due to insufficient accuracy.
  This is due to unique challenges in the behavioral health domain, including very
  small datasets ($\sim \!\! 10^1$ participants), which frequently contain missing
  data, consist of long time series with critical long-range dependencies (length$<10^4$),
  and extreme class imbalances ($>10^3$:1). Here, we \new{describe} a neural architecture
  for multivariate time series classification designed to address these unique domain
  challenges. Our proposed behavioral representation learning approach combines novel
  tasks for self-supervised pretraining and transfer learning to address data scarcity,  and
  captures long-range dependencies across long-history time series through transformer
  self-attention following convolutional neural network-based dimensionality reduction.
  We propose an evaluation framework aimed at reflecting expected real-world performance
  in plausible deployment scenarios. Concretely, we demonstrate (1) performance improvements
  over baselines of up to 0.15 ROC AUC across five influenza-related prediction tasks,
  (2) transfer learning-induced performance improvements \new{including a 16% relative
  increase} in PR AUC in small data scenarios, and (3) the potential of transfer learning
  in novel disease scenarios through an exploratory case study of zero-shot COVID-19
  prediction in an independent data set.  Finally, we discuss potential implications
  for medical surveillance testing.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: merrill23a
month: 0
tex_title: Self-Supervised Pretraining and Transfer Learning Enable\titlebreak Flu
  and COVID-19 Predictions in Small Mobile Sensing Datasets
firstpage: 191
lastpage: 206
page: 191-206
order: 191
cycles: false
bibtex_author: Merrill, Mika A and Althoff, Tim
author:
- given: Mika A
  family: Merrill
- given: Tim
  family: Althoff
date: 2023-06-13
address:
container-title: Proceedings of the Conference on Health, Inference, and Learning
volume: '209'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 13
pdf: https://proceedings.mlr.press/v209/merrill23a/merrill23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
